{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f00588f-6a28-4d93-b072-f464f78aae40",
   "metadata": {},
   "source": [
    "# Using ModelBuilder class for deploying PyMC models \n",
    ":::{post} Feb 22, 2023\n",
    ":tags: deployment\n",
    ":category: advanced\n",
    ":author: Shashank Kirtania, Thomas Wiecki, Michał Raczycki\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdfb702-b893-4e63-8354-935f9742fdde",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a7e0ee-506c-4d5d-adb3-a52cc24cac50",
   "metadata": {},
   "source": [
    "Many users face difficulty in deploying their PyMC models to production because deploying/saving/loading a user-created model is not well standardized. One of the reasons behind this is there is no direct way to save or load a model in PyMC like scikit-learn or TensorFlow. The new `ModelBuilder` class is aimed to improve this workflow by providing a scikit-learn inspired API to wrap your PyMC models.\n",
    "\n",
    "The new {class}`ModelBuilder <pymc_extras.model_builder.ModelBuilder>` class allows users to use methods to `fit()`, `predict()`, `save()`, `load()`. Users can create any model they want, inherit the {class}`ModelBuilder <pymc_extras.model_builder.ModelBuilder>` class, and use predefined methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94832375-dc7e-4b4f-ad2e-87363fc363db",
   "metadata": {},
   "source": [
    "Let's go through the full workflow, starting with a simple linear regression PyMC model as it's usually written. Of course, this model is just a place-holder for your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e35045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not available, if using conda: `conda install gxx`\n",
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import xarray as xr\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "RANDOM_SEED = 8927\n",
    "\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6eccf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "x = np.linspace(start=0, stop=1, num=100)\n",
    "y = 0.3 * x + 0.5 + rng.normal(0, 1, len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291452ed",
   "metadata": {},
   "source": [
    "## Standard syntax\n",
    "Usually a PyMC model will have this form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d07dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b, eps]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b746f2492f44496db6343313b8cef556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 173 seconds.\n",
      "Sampling: [a, b, eps, y_model]\n",
      "Sampling: [y_model]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c844875f7c43405d963339305bd60a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    # priors\n",
    "    a = pm.Normal(\"a\", mu=0, sigma=1)\n",
    "    b = pm.Normal(\"b\", mu=0, sigma=1)\n",
    "    eps = pm.HalfNormal(\"eps\", 1.0)\n",
    "\n",
    "    # observed data\n",
    "    y_model = pm.Normal(\"y_model\", mu=a + b * x, sigma=eps, observed=y)\n",
    "\n",
    "    # Fitting\n",
    "    idata = pm.sample()\n",
    "    idata.extend(pm.sample_prior_predictive())\n",
    "\n",
    "    # posterior predict\n",
    "    idata.extend(pm.sample_posterior_predictive(idata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda28484",
   "metadata": {},
   "source": [
    "How would we deploy this model? Save the fitted model, load it on an instance, and predict? Not so simple.\n",
    "\n",
    "`ModelBuilder` is built for this purpose. It is currently part of the {ref}`pymc-experimental` package which we can pip install with `pip install pymc-experimental`. As the name implies, this feature is still experimental and subject to change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213ee05a",
   "metadata": {},
   "source": [
    "## Model builder class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36214695-5fb1-4450-a3ea-789f2e965746",
   "metadata": {},
   "source": [
    "Let's import the `ModelBuilder` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1f5fa98-53d8-459a-827b-fa5179861918",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymc_extras'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpymc_extras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelBuilder\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pymc_extras'"
     ]
    }
   ],
   "source": [
    "from pymc_extras.model_builder import ModelBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0412fe-5aae-4bfa-8a1f-0e1e3762fc5f",
   "metadata": {},
   "source": [
    "To define our desired model we inherit from the `ModelBuilder` class. There are a couple of methods we need to define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b4575-630c-45a7-9eee-4790adf8924f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LinearModel(ModelBuilder):\n",
    "    # Give the model a name\n",
    "    _model_type = \"LinearModel\"\n",
    "\n",
    "    # And a version\n",
    "    version = \"0.1\"\n",
    "\n",
    "    def build_model(self, X: pd.DataFrame, y: pd.Series, **kwargs):\n",
    "        \"\"\"\n",
    "        Creates the PyMC model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            The input data (predictors). Should contain the features required\n",
    "            by the model.\n",
    "        y : pd.Series\n",
    "            The target data (dependent variable).\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments. These are currently unused in this\n",
    "            example but are accepted for API compatibility.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        Model configuration parameters (e.g., prior locations and scales)\n",
    "        are accessed via `self.model_config`, which is initialized during\n",
    "        class instantiation by the base `ModelBuilder` class.\n",
    "        \"\"\"\n",
    "        # Check the type of X and y and adjust access accordingly\n",
    "        X_values = X[\"input\"].values\n",
    "        y_values = y.values if isinstance(y, pd.Series) else y\n",
    "        self._generate_and_preprocess_model_data(X_values, y_values)\n",
    "\n",
    "        with pm.Model(coords=self.model_coords) as self.model:\n",
    "            # Create mutable data containers\n",
    "            x_data = pm.MutableData(\"x_data\", X_values)\n",
    "            y_data = pm.MutableData(\"y_data\", y_values)\n",
    "\n",
    "            # prior parameters\n",
    "            a_mu_prior = self.model_config.get(\"a_mu_prior\", 0.0)\n",
    "            a_sigma_prior = self.model_config.get(\"a_sigma_prior\", 1.0)\n",
    "            b_mu_prior = self.model_config.get(\"b_mu_prior\", 0.0)\n",
    "            b_sigma_prior = self.model_config.get(\"b_sigma_prior\", 1.0)\n",
    "            eps_prior = self.model_config.get(\"eps_prior\", 1.0)\n",
    "\n",
    "            # priors\n",
    "            a = pm.Normal(\"a\", mu=a_mu_prior, sigma=a_sigma_prior)\n",
    "            b = pm.Normal(\"b\", mu=b_mu_prior, sigma=b_sigma_prior)\n",
    "            eps = pm.HalfNormal(\"eps\", eps_prior)\n",
    "\n",
    "            obs = pm.Normal(\"y\", mu=a + b * x_data, sigma=eps, shape=x_data.shape, observed=y_data)\n",
    "\n",
    "    def _data_setter(\n",
    "        self, X: Union[pd.DataFrame, np.ndarray], y: Union[pd.Series, np.ndarray] = None\n",
    "    ):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            x_values = X[\"input\"].values\n",
    "        else:\n",
    "            # Assuming \"input\" is the first column\n",
    "            x_values = X[:, 0]\n",
    "\n",
    "        with self.model:\n",
    "            pm.set_data({\"x_data\": x_values})\n",
    "            if y is not None:\n",
    "                pm.set_data({\"y_data\": y.values if isinstance(y, pd.Series) else y})\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_model_config() -> Dict:\n",
    "        \"\"\"\n",
    "        Returns a class default config dict for model builder if no model_config is provided on class initialization.\n",
    "        The model config dict is generally used to specify the prior values we want to build the model with.\n",
    "        It supports more complex data structures like lists, dictionaries, etc.\n",
    "        It will be passed to the class instance on initialization, in case the user doesn't provide any model_config of their own.\n",
    "        \"\"\"\n",
    "        model_config: Dict = {\n",
    "            \"a_mu_prior\": 0.0,\n",
    "            \"a_sigma_prior\": 1.0,\n",
    "            \"b_mu_prior\": 0.0,\n",
    "            \"b_sigma_prior\": 1.0,\n",
    "            \"eps_prior\": 1.0,\n",
    "        }\n",
    "        return model_config\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_sampler_config() -> Dict:\n",
    "        \"\"\"\n",
    "        Returns a class default sampler dict for model builder if no sampler_config is provided on class initialization.\n",
    "        The sampler config dict is used to send parameters to the sampler .\n",
    "        It will be used during fitting in case the user doesn't provide any sampler_config of their own.\n",
    "        \"\"\"\n",
    "        sampler_config: Dict = {\n",
    "            \"draws\": 1_000,\n",
    "            \"tune\": 1_000,\n",
    "            \"chains\": 3,\n",
    "            \"target_accept\": 0.95,\n",
    "        }\n",
    "        return sampler_config\n",
    "\n",
    "    @property\n",
    "    def output_var(self):\n",
    "        return \"y\"\n",
    "\n",
    "    @property\n",
    "    def _serializable_model_config(self) -> Dict[str, Union[int, float, Dict]]:\n",
    "        \"\"\"\n",
    "        _serializable_model_config is a property that returns a dictionary with all the model parameters that we want to save.\n",
    "        as some of the data structures are not json serializable, we need to convert them to json serializable objects.\n",
    "        Some models will need them, others can just define them to return the model_config.\n",
    "        \"\"\"\n",
    "        return self.model_config\n",
    "\n",
    "    def _save_input_params(self, idata) -> None:\n",
    "        \"\"\"\n",
    "        Saves any additional model parameters (other than the dataset) to the idata object.\n",
    "\n",
    "        These parameters are stored within `idata.attrs` using keys that correspond to the parameter names.\n",
    "        If you don't need to store any extra parameters, you can leave this method unimplemented.\n",
    "\n",
    "        Example:\n",
    "            For saving customer IDs provided as an 'customer_ids' input to the model:\n",
    "            self.customer_ids = customer_ids.values #this line is done outside of the function, preferably at the initialization of the model object.\n",
    "            idata.attrs[\"customer_ids\"] = json.dumps(self.customer_ids.tolist())  # Convert numpy array to a JSON-serializable list.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _generate_and_preprocess_model_data(\n",
    "        self, X: Union[pd.DataFrame, pd.Series], y: Union[pd.Series, np.ndarray]\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Depending on the model, we might need to preprocess the data before fitting the model.\n",
    "        all required preprocessing and conditional assignments should be defined here.\n",
    "        \"\"\"\n",
    "        self.model_coords = None  # in our case we're not using coords, but if we were, we would define them here, or later on in the function, if extracting them from the data.\n",
    "        # as we don't do any data preprocessing, we just assign the data given by the user. Note that it's a very basic model,\n",
    "        # and usually we would need to do some preprocessing, or generate the coords from the data.\n",
    "        self.X = X\n",
    "        self.y = y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa682cee-58b0-4c51-b5fd-f99d6afaea69",
   "metadata": {},
   "source": [
    "Now we can create the `LinearModel` object. First step we need to take care of, is data generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8658306c-f1eb-45a7-9c71-3fcee06183bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data=np.linspace(start=0, stop=1, num=100), columns=[\"input\"])\n",
    "y = 0.3 * x + 0.5\n",
    "y = y + np.random.normal(0, 1, len(x))\n",
    "\n",
    "model = LinearModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294cf57b-b51f-4c77-8e0b-5adaf0a63f2b",
   "metadata": {},
   "source": [
    "After making the object of class `LinearModel` we can fit the model using the `.fit()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4dead3",
   "metadata": {},
   "source": [
    "## Fitting to data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e50eb992",
   "metadata": {},
   "source": [
    "The `fit()` method takes one argument `data` on which we need to fit the model. The meta-data is saved in the `InferenceData` object where also the trace is stored. These are the fields that are stored:\n",
    "\n",
    "* `id` : This is a unique id given to a model based on model_config, sample_conifg, version, and model_type. Users can use it to check if the model matches to another model they have defined.\n",
    "* `model_type` : Model type tells us what kind of model it is. This in this case it outputs **Linear Model** \n",
    "* `version` : In case you want to improve on models, you can keep track of model by their version. As the version changes the unique hash in the `id` also changes.\n",
    "* `sample_conifg` : It stores values of the sampler configuration set by user for this particular model.\n",
    "* `model_config` : It stores values of the model configuration set by user for this particular model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3708a8f-40f6-4a04-bcbf-284397f25450",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac975628",
   "metadata": {},
   "source": [
    "## Saving model to file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1649556a-13b6-409f-ac09-5c4b7e0277b7",
   "metadata": {},
   "source": [
    "After fitting the model, we can probably save it to share the model as a file so one can use it again.\n",
    "To `save()` or `load()`, we can quickly call methods for respective tasks with the following syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a965d738-60c5-4b4b-b872-f2613621851b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fname = \"linear_model_v1.nc\"\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490e8802-0395-42c7-a01a-18d9af272320",
   "metadata": {},
   "source": [
    "This saves a file at the given path, and the name <br>\n",
    "A NetCDF `.nc` file that stores the inference data of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf072612",
   "metadata": {},
   "source": [
    "## Loading a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e188eb0-c42e-4cd5-b70c-568d9cde71f0",
   "metadata": {},
   "source": [
    "Now if we wanted to deploy this model, or just have other people use it to predict data, they need two things:\n",
    "1. the `LinearModel` class (probably in a .py file)\n",
    "2. the linear_model_v1.nc file\n",
    "\n",
    "With these, you can easily load a fitted model in a different environment (e.g. production):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2bccf2-1707-4b21-803b-50716e9298c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = LinearModel.load(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ac7c8f",
   "metadata": {},
   "source": [
    "Note that `load()` is a class-method, we do not need to instantiate the `LinearModel` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc1840c",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7254f1-7a59-4623-a128-8a1dd48d0407",
   "metadata": {},
   "source": [
    "Next we might want to predict on new data. The `predict()` method allows users to do posterior prediction with the fitted model on new data.\n",
    "\n",
    "Our first task is to create data on which we need to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecc8694-db5e-4d45-b8e0-78608b7eaa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.random.uniform(low=1, high=2, size=10)\n",
    "prediction_data = pd.DataFrame({\"input\": x_pred})\n",
    "type(prediction_data[\"input\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b155d2d-0211-4d85-8b60-a728a62e3743",
   "metadata": {},
   "source": [
    "`ModelBuilder` provides two methods for prediction:\n",
    "1. point estimates (the mean) with `predict()`\n",
    "2. full posterior prediction (samples) with `predict_posterior()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6926eba3-52ed-4c6c-b58f-f2e0bba7b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean = model_2.predict(prediction_data)\n",
    "# samples\n",
    "pred_samples = model_2.predict_posterior(prediction_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb595b5-e237-4099-b16d-f00c4448307e",
   "metadata": {},
   "source": [
    "After using the `predict()`, we can plot our data and see graphically how satisfactory our `LinearModel` is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5375a1c-ed19-4e06-9d9f-74369877cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "posterior = az.extract(idata, num_samples=20)\n",
    "x_plot = xr.DataArray(np.linspace(1, 2, 100))\n",
    "y_plot = posterior[\"b\"] * x_plot + posterior[\"a\"]\n",
    "Line2 = ax.plot(x_plot, y_plot.transpose(), color=\"C1\")\n",
    "Line1 = ax.plot(x_pred, pred_mean, \"x\")\n",
    "ax.set(title=\"Posterior predictive regression lines\", xlabel=\"x\", ylabel=\"y\")\n",
    "ax.legend(\n",
    "    handles=[Line1[0], Line2[0]], labels=[\"predicted average\", \"inferred regression line\"], loc=0\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fb64ed-f707-4e19-9e27-b0c2700c04f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w -p pymc_experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917782b",
   "metadata": {},
   "source": [
    "## Authors\n",
    "* Authored by Shashank Kirtania and Thomas Wiecki in 2023.\n",
    "* Modified and updated by Michał Raczycki in 08/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab6cda6",
   "metadata": {},
   "source": [
    ":::{include} ../page_footer.md\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
