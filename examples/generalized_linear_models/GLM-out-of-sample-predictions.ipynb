{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(GLM-out-of-sample-predictions)=\n",
    "# Out-Of-Sample Predictions\n",
    "\n",
    ":::{post} June, 2022\n",
    ":tags: generalized linear model, logistic regression, out of sample predictions, patsy\n",
    ":category: beginner\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many applications we require doing predictions on out-of-sample data. This experiment was motivated by the discussion of the thread [\"Out of sample\" predictions with the GLM sub-module](https://discourse.pymc.io/t/out-of-sample-predictions-with-the-glm-sub-module/773) on the (great!) forum [discourse.pymc.io/](https://discourse.pymc.io/), thank you all for your input! But note that this GLM sub-module was deprecated in favour of [`bambi`](https://github.com/bambinos/bambi). But this notebook implements a 'raw' PyMC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "import pymc as pm\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.special import expit as inverse_logit\n",
    "from sklearn.metrics import RocCurveDisplay, accuracy_score, auc, roc_curve\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 8927\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Data\n",
    "\n",
    "We want to fit a logistic regression model where there is a multiplicative interaction between two numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data points\n",
    "n = 250\n",
    "# Create features\n",
    "x1 = rng.normal(loc=0.0, scale=2.0, size=n)\n",
    "x2 = rng.normal(loc=0.0, scale=2.0, size=n)\n",
    "# Define target variable\n",
    "intercept = -0.5\n",
    "beta_x1 = 1\n",
    "beta_x2 = -1\n",
    "beta_interaction = 2\n",
    "z = intercept + beta_x1 * x1 + beta_x2 * x2 + beta_interaction * x1 * x2\n",
    "p = inverse_logit(z)\n",
    "# note binimial with n=1 is equal to a bernoulli\n",
    "y = rng.binomial(n=1, p=p, size=n)\n",
    "df = pd.DataFrame(dict(x1=x1, x2=x2, y=y))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us do some exploration of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df, kind=\"scatter\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $x_1$ and $x_2$ are not correlated.\n",
    "- $x_1$ and $x_2$ do not seem to separate the $y$-classes independently.\n",
    "- The distribution of $y$ is not highly unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns_c_div = sns.diverging_palette(240, 10, n=2)\n",
    "sns.scatterplot(x=\"x1\", y=\"x2\", data=df, hue=\"y\", palette=[sns_c_div[0], sns_c_div[-1]])\n",
    "ax.legend(title=\"y\")\n",
    "ax.set(title=\"Sample Data\", xlim=(-9, 9), ylim=(-9, 9));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = patsy.dmatrices(\"y ~ x1 * x2\", data=df)\n",
    "y = np.asarray(y).flatten()\n",
    "labels = x.design_info.column_names\n",
    "x = np.asarray(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Fit the Model\n",
    "\n",
    "We now specify the model in PyMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COORDS = {\"coeffs\": [\"b0\", \"b1\", \"b2\", \"b1:b2\"]}\n",
    "\n",
    "with pm.Model(coords=COORDS) as model:\n",
    "    # data containers\n",
    "    X = pm.MutableData(\"X\", x_train)\n",
    "    y = pm.MutableData(\"y\", y_train)\n",
    "    # priors\n",
    "    b = pm.Normal(\"b\", mu=0, sigma=1, dims=\"coeffs\")\n",
    "    # linear model\n",
    "    mu = pm.math.dot(X, b)\n",
    "    # link function\n",
    "    p = pm.Deterministic(\"p\", pm.math.invlogit(mu))\n",
    "    # likelihood\n",
    "    pm.Bernoulli(\"obs\", p=p, observed=y)\n",
    "\n",
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    idata = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata, var_names=\"b\", compact=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chains look good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, var_names=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we do a good job of recovering the true parameters for this simulated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(\n",
    "    idata, var_names=[\"b\"], ref_val=[intercept, beta_x1, beta_x2, beta_interaction], figsize=(15, 4)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Out-Of-Sample Predictions\n",
    "\n",
    "Now we generate predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    pm.set_data({\"X\": x_test, \"y\": y_test})\n",
    "    idata.extend(pm.sample_posterior_predictive(idata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the point prediction by taking the mean and defining the category via a threshold.\n",
    "p_test_pred = idata.posterior_predictive[\"obs\"].mean(dim=[\"chain\", \"draw\"])\n",
    "y_test_pred = (p_test_pred >= 0.5).astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "First let us compute the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"accuracy = {accuracy_score(y_true=y_test, y_pred=y_test_pred): 0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we plot the [roc curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) and compute the [auc](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(\n",
    "    y_true=y_test, y_score=p_test_pred, pos_label=1, drop_intermediate=False\n",
    ")\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n",
    "roc_display = roc_display.plot(ax=ax, marker=\"o\", markersize=4)\n",
    "ax.set(title=\"ROC\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is performing as expected (we of course know the data generating process, which is almost never the case in practical applications)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Decision Boundary\n",
    "\n",
    "Finally we will describe and plot the model decision boundary, which is the space defined as\n",
    "\n",
    "$$\\mathcal{B} = \\{(x_1, x_2) \\in \\mathbb{R}^2 \\: | \\: p(x_1, x_2) = 0.5\\}$$\n",
    "\n",
    "where $p$ denotes the probability of belonging to the class $y=1$ output by the model. To make this set explicit, we simply write the condition in terms of the model parametrization:\n",
    "\n",
    "$$0.5 = \\frac{1}{1 + \\exp(-(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_{12} x_1x_2))}$$\n",
    "\n",
    "which implies\n",
    "\n",
    "$$0 = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_{12} x_1x_2$$\n",
    "\n",
    "Solving for $x_2$ we get the formula\n",
    "\n",
    "$$x_2 = - \\frac{\\beta_0 + \\beta_1 x_1}{\\beta_2 + \\beta_{12}x_1}$$\n",
    "\n",
    "Observe that this curve is a hyperbola centered at the singularity point $x_1 = - \\beta_2 / \\beta_{12}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now plot the model decision boundary using a grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid():\n",
    "    x1_grid = np.linspace(start=-9, stop=9, num=300)\n",
    "    x2_grid = x1_grid\n",
    "    x1_mesh, x2_mesh = np.meshgrid(x1_grid, x2_grid)\n",
    "    x_grid = np.stack(arrays=[x1_mesh.flatten(), x2_mesh.flatten()], axis=1)\n",
    "    return x1_grid, x2_grid, x_grid\n",
    "\n",
    "\n",
    "x1_grid, x2_grid, x_grid = make_grid()\n",
    "\n",
    "with model:\n",
    "    # Create features on the grid.\n",
    "    x_grid_ext = patsy.dmatrix(formula_like=\"x1 * x2\", data=dict(x1=x_grid[:, 0], x2=x_grid[:, 1]))\n",
    "    x_grid_ext = np.asarray(x_grid_ext)\n",
    "    # set the observed variables\n",
    "    pm.set_data({\"X\": x_grid_ext})\n",
    "    # calculate pushforward values of `p`\n",
    "    ppc_grid = pm.sample_posterior_predictive(idata, var_names=[\"p\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid of predictions\n",
    "grid_df = pd.DataFrame(x_grid, columns=[\"x1\", \"x2\"])\n",
    "grid_df[\"p\"] = ppc_grid.posterior_predictive.p.mean(dim=[\"chain\", \"draw\"])\n",
    "# grid_df.sort_values(\"p\", inplace=True)\n",
    "p_grid = grid_df.pivot(index=\"x2\", columns=\"x1\", values=\"p\").to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the model decision boundary on the grid for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_decision_boundary(idata, x1_grid):\n",
    "    # posterior mean of coefficients\n",
    "    intercept = idata.posterior.b.sel(coeffs=\"Intercept\").mean().data\n",
    "    x1 = idata.posterior.b.sel(coeffs=\"x1\").mean().data\n",
    "    x2 = idata.posterior.b.sel(coeffs=\"x2\").mean().data\n",
    "    x1x2 = idata.posterior.b.sel(coeffs=\"x1:x2\").mean().data\n",
    "    # decision boundary equation\n",
    "    return -(intercept + x1 * x1_grid) / (x2 + x1x2 * x1_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally get the plot and the predictions on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cmap = sns.diverging_palette(240, 10, n=50, as_cmap=True)\n",
    "\n",
    "# data\n",
    "sns.scatterplot(\n",
    "    x=x_test[:, 1].flatten(),\n",
    "    y=x_test[:, 2].flatten(),\n",
    "    hue=y_test,\n",
    "    palette=[sns_c_div[0], sns_c_div[-1]],\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "# decision boundary\n",
    "ax.plot(x1_grid, calc_decision_boundary(idata, x1_grid), color=\"black\", linestyle=\":\")\n",
    "\n",
    "# grid of predictions\n",
    "ax.contourf(x1_grid, x2_grid, p_grid, alpha=0.3, cmap=cmap)\n",
    "\n",
    "ax.legend(title=\"y\", loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "ax.set(title=\"Model Decision Boundary\", xlim=(-9, 9), ylim=(-9, 9), xlabel=\"x1\", ylabel=\"x2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have computed the model decision boundary by using the mean of the posterior samples. However, we can generate a better (and more informative!) plot if we use the complete distribution (similarly for other metrics like accuracy and AUC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Bambi](https://bambinos.github.io/bambi/), a more complete implementation of the GLM submodule which also allows for mixed-effects models.\n",
    "- [Bayesian Analysis with Python (Second edition) - Chapter 4](https://github.com/aloctavodia/BAP/blob/master/code/Chp4/04_Generalizing_linear_models.ipynb)\n",
    "- [Statistical Rethinking](https://xcelab.net/rm/statistical-rethinking/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "- Created by [Juan Orduz](https://github.com/juanitorduz).\n",
    "- Updated by [Benjamin T. Vincent](https://github.com/drbenvincent) to PyMC v4 in June 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w -p aesara,aeppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{include} ../page_footer.md :::"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16e496db1b87424c0886458748666213e8028907aea10f58bf3c3f4c68e32b3b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pymc-dev-py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
