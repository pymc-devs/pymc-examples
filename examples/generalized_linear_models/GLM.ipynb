{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Generalized) Linear and Hierarchical Linear Models in PyMC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import statsmodels.api as sm\n",
    "import theano\n",
    "import bambi\n",
    "from numpy.random import default_rng\n",
    "from pandas.plotting import scatter_matrix\n",
    "from pymc3 import *\n",
    "from statsmodels.formula.api import glm as glm_sm\n",
    "\n",
    "print(f\"Running on PyMC3 v{pm.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "# Initialize random number generator\n",
    "RANDOM_SEED = 8927\n",
    "rng = default_rng(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "Lets generate some data with known slope and intercept and fit a simple linear GLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 50\n",
    "true_intercept = 1\n",
    "true_slope = 2\n",
    "x = np.linspace(0, 1, size)\n",
    "y = true_intercept + x * true_slope + rng.normal(scale=0.5, size=size)\n",
    "data = {\"x\": x, \"y\": y}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `glm.linear_component()` function can be used to generate the output variable y_est and coefficients of the specified linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Model() as model:\n",
    "    lm = glm.LinearComponent.from_formula(\"y ~ x\", data)\n",
    "    sigma = Uniform(\"sigma\", 0, 20)\n",
    "    y_obs = Normal(\"y_obs\", mu=lm.y_est, sigma=sigma, observed=y)\n",
    "    trace = pm.sample(2000, cores=2, return_inferencedata=True)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x, y, \"x\")\n",
    "plot_posterior_predictive_glm(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are a couple of general linear models that are being used over and over again (Normally distributed noise, logistic regression etc), the `glm.glm()` function simplifies the above step by creating the likelihood (y_obs) and its priors (sigma) for us. Since we are working in the model context, the random variables are all added to the model behind the scenes. This function also automatically finds a good starting point which it returns.\n",
    "\n",
    "Note that the below call to `glm()` is producing exactly the same model as above, just more succinctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Model() as model:\n",
    "    GLM.from_formula(\"y ~ x\", data)\n",
    "    trace = pm.sample(2000, cores=2, return_inferencedata=True)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x, y, \"x\")\n",
    "plot_posterior_predictive_glm(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust GLM\n",
    "\n",
    "Lets try the same model but with a few outliers in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = np.append(x, [0.1, 0.15, 0.2])\n",
    "y_out = np.append(y, [8, 6, 9])\n",
    "data_outlier = dict(x=x_out, y=y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Model() as model:\n",
    "    GLM.from_formula(\"y ~ x\", data_outlier)\n",
    "    trace = pm.sample(2000, cores=2, return_inferencedata=True)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x_out, y_out, \"x\")\n",
    "plot_posterior_predictive_glm(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the normal distribution does not have a lot of mass in the tails, an outlier will affect the fit strongly.\n",
    "\n",
    "Instead, we can replace the Normal likelihood with a student T distribution which has heavier tails and is more robust towards outliers. While this could be done with the `linear_compoment()` function and manually defining the T likelihood we can use the `glm()` function for more automation. By default this function uses a normal likelihood. To define the usage of a T distribution instead we can pass a family object that contains information on how to link the output to `y_est` (in this case we explicitly use the Identity link function which is also the default) and what the priors for the T distribution are. Here we fix the degrees of freedom `nu` to 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Model() as model_robust:\n",
    "    family = glm.families.StudentT(\n",
    "        link=glm.families.Identity(), priors={\"nu\": 1.5, \"lam\": Uniform.dist(0, 20)}\n",
    "    )\n",
    "    GLM.from_formula(\"y ~ x\", data_outlier, family=family)\n",
    "    trace = pm.sample(2000, cores=2, return_inferencedata=True)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x_out, y_out, \"x\")\n",
    "plot_posterior_predictive_glm(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sat_data = pd.read_csv(\"../data/Guber1999data.txt\")\n",
    "except:\n",
    "    sat_data = pd.read_csv(pm.get_data(\"Guber1999data.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mean = bambi.Prior(\"Normal\", mu=0, sigma=10)\n",
    "grp_sd = bambi.Prior('HalfCauchy', beta=5)\n",
    "\n",
    "priors = {'Intercept': bambi.Prior('Normal',mu=sat_data.sat_t.mean(), sigma=sat_data.sat_t.std()),\n",
    "          '1|spend': bambi.Prior('Normal', mu=grp_mean, sigma=grp_sd),\n",
    "          '1|stu_tea_rat':bambi.Prior('Normal',mu=grp_mean, sigma=grp_sd), \n",
    "          '1|salary': bambi.Prior('Normal', mu=grp_mean, sigma=grp_sd),\n",
    "          '1|prcnt_take':bambi.Prior('Normal', mu=grp_mean, sigma=grp_sd)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bambi.Model(\"sat_t ~ (1|spend) + (1|stu_tea_rat) + (1|salary) + (1|prcnt_take)\", sat_data,priors=priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(draws=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(results.to_dataframe, figsize=(12, 12));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Model() as model_sat:\n",
    "    grp_mean = Normal(\"grp_mean\", mu=0, sigma=10)\n",
    "    grp_prec = Gamma(\"grp_prec\", alpha=1, beta=0.1, testval=1.0)\n",
    "    slope = StudentT.dist(mu=grp_mean, lam=grp_prec, nu=1)\n",
    "    intercept = Normal.dist(mu=sat_data.sat_t.mean(), sigma=sat_data.sat_t.std())\n",
    "    GLM.from_formula(\n",
    "        \"sat_t ~ spend + stu_tea_rat + salary + prcnt_take\",\n",
    "        sat_data,\n",
    "        priors={\"Intercept\": intercept, \"Regressor\": slope},\n",
    "    )\n",
    "    trace_sat = sample(2000, cores=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(trace_to_dataframe(trace_sat), figsize=(12, 12));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_gain = 5.0\n",
    "with Model() as model_sat:\n",
    "    grp_mean = Normal(\"grp_mean\", mu=0, sigma=10)\n",
    "    grp_prec = Gamma(\"grp_prec\", alpha=1, beta=0.1, testval=1.0)\n",
    "    slope = StudentT.dist(mu=grp_mean, lam=grp_prec, nu=1)  # grp_df)\n",
    "    intercept = Normal.dist(mu=sat_data.sat_t.mean(), sigma=sat_data.sat_t.std())\n",
    "    GLM.from_formula(\n",
    "        \"sat_t ~ spend + stu_tea_rat + salary + prcnt_take\",\n",
    "        sat_data,\n",
    "        priors={\"Intercept\": intercept, \"Regressor\": slope},\n",
    "    )\n",
    "\n",
    "    trace_sat = sample(2000, cores=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(trace_to_dataframe(trace_sat), figsize=(12, 12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htwt_data = pd.read_csv(get_data(\"HtWt.csv\"))\n",
    "htwt_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = glm_sm(\"male ~ height + weight\", htwt_data, family=sm.families.Binomial()).fit()\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Model() as model_htwt:\n",
    "    GLM.from_formula(\"male ~ height + weight\", htwt_data, family=glm.families.Binomial())\n",
    "    trace_htwt = sample(\n",
    "        2000, cores=2, init=\"adapt_diag\"\n",
    "    )  # default init with jitter can cause problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_df = trace_to_dataframe(trace_htwt)\n",
    "print(trace_df.describe().drop(\"count\").T)\n",
    "scatter_matrix(trace_df, figsize=(8, 8))\n",
    "print(\"P(weight < 0) = \", (trace_df[\"weight\"] < 0).mean())\n",
    "print(\"P(height < 0) = \", (trace_df[\"height\"] < 0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Logistic Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp = Laplace.dist(mu=0, b=0.05)\n",
    "x_eval = np.linspace(-0.5, 0.5, 300)\n",
    "plt.plot(x_eval, theano.tensor.exp(lp.logp(x_eval)).eval())\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(\"Laplace distribution\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Model() as model_lasso:\n",
    "    # Define priors for intercept and regression coefficients.\n",
    "    priors = {\"Intercept\": Normal.dist(mu=0, sigma=50), \"Regressor\": Laplace.dist(mu=0, b=0.05)}\n",
    "    GLM.from_formula(\n",
    "        \"male ~ height + weight\", htwt_data, family=glm.families.Binomial(), priors=priors\n",
    "    )\n",
    "\n",
    "    trace_lasso = sample(500, cores=2, init=\"adapt_diag\")\n",
    "\n",
    "trace_df = trace_to_dataframe(trace_lasso)\n",
    "scatter_matrix(trace_df, figsize=(8, 8))\n",
    "print(trace_df.describe().drop(\"count\").T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
